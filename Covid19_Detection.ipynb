{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\n\nbase_dir = '../input/covid19-image-dataset/Covid19-dataset'\n\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lstnames = os.listdir(train_dir)\ntest_lstnames = os.listdir(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lstnames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_types_dir = []\nfor idx, type_name in enumerate(train_lstnames):\n    type_dir = os.path.join(train_dir, type_name)\n    train_types_dir.append(type_dir)\n\ntest_types_dir = [] \nfor idx, type_name in enumerate(test_lstnames):\n    type_dir = os.path.join(test_dir, type_name)\n    test_types_dir.append(type_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_per_type = {}\n\nfor idx, train_type_dir in enumerate(train_types_dir):\n    num_spec = len(os.listdir(train_type_dir))\n    type_name = train_lstnames[idx]\n    number_per_type[type_name] = num_spec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_number_df = pd.DataFrame(data=[number_per_type[i] for i in number_per_type.keys()], index=number_per_type.keys(), columns=['Quantity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_number_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_number_df.plot(kind = 'bar', x = None, y = 'Quantity', figsize = (20, 10), title = 'Number of image for each type', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_number_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_random_image(train_lstnames, number_random_types, number_random_per_types, train_types_dir, df):\n    types_idx = np.random.choice(np.arange(len(train_lstnames)), number_random_types, replace = False)\n\n    next_image = {}\n    for idx in types_idx:\n        label = train_lstnames[idx]\n        lst_name = os.listdir(train_types_dir[idx])\n        random_idxs = np.random.choice(int(df.loc[df.index.values[idx]].values), number_random_per_types, replace = False)\n        choose_image = []\n        for image_idx in random_idxs:\n            img_name = os.path.join(train_types_dir[idx], lst_name[image_idx])\n            choose_image.append(img_name)\n        next_image[label] = choose_image\n        \n    return next_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image(number_random_types, number_random_per_types, image_size, next_image, class_names = None, model  = None, get_prediction = False):\n    fig = plt.gcf()\n\n    nrows = number_random_types\n    ncols = number_random_per_types\n\n    fig.set_size_inches(image_size*nrows, image_size*ncols)\n    \n    if not get_prediction:\n        model = None\n        class_names = None\n    else:\n        inverse_class_names = {}\n        for k, v in class_names.items():\n            inverse_class_names[int(v)] = k\n        \n    count = 0\n    for label, img_paths in next_image.items():\n        for img_path in img_paths:\n            sb = plt.subplot(nrows, ncols, count + 1)\n            img = mpimg.imread(img_path)\n            shape = img.shape\n            sb.set_title(f'{label}, {shape}', color = 'r')\n            \n            if get_prediction:\n                from tensorflow.keras.preprocessing.image import img_to_array\n                import cv2\n                new_img = cv2.resize(img, (224, 224))\n                new_img = img_to_array(img)\n                new_img = np.expand_dims(img, axis = 0)\n\n                std_img = new_img / 255.0\n                pred = model.predict(std_img)\n                print('Prediction', np.argmax(pred))\n                pred_name = inverse_class_names[int(np.argmax(pred))]\n                sb.set_title(f'Predicted: {pred_name} \\nGround True: {label}', color = 'r', fontsize = 10)\n                \n            sb.axis('Off')\n            \n            plt.imshow(img)\n            count += 1\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.image as mpimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_random_types = 3\nnumber_random_per_types = 4\n\nnext_image = generate_random_image(train_lstnames, number_random_types, number_random_per_types, train_types_dir, type_number_df)\nplot_image(number_random_types, number_random_per_types, 5, next_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef get_train_generator(image_dir, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    print(\"getting train generator...\")\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True, \n        shear_range=0.1,\n        zoom_range=0.15,\n        rotation_range=5,\n        width_shift_range=0.1,\n        height_shift_range=0.05,\n        horizontal_flip=True, \n        vertical_flip = False, \n        fill_mode = 'reflect')\n    \n    generator = image_generator.flow_from_directory(\n            directory= image_dir,\n            class_mode=\"categorical\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_generator(train_image_dir, image_dir, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_directory(\n        directory=train_image_dir,  \n        class_mode=\"categorical\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    test_generator = image_generator.flow_from_directory(\n            directory=image_dir,\n            class_mode=\"categorical\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return test_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE=[320, 320]\n\nEPOCHS = 20\n\nVAL_BATCH_SIZE = 16\n\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = get_train_generator(\n                                      image_dir = train_dir, \n                                      batch_size=BATCH_SIZE,\n                                      target_w = IMAGE_SIZE[0], \n                                      target_h = IMAGE_SIZE[1] \n                                      )\ntest_generator= get_test_generator(train_image_dir = train_dir, \n                                                    image_dir = test_dir, \n                                                    batch_size = VAL_BATCH_SIZE,\n                                                    target_w = IMAGE_SIZE[0], \n                                                    target_h = IMAGE_SIZE[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (320, 320, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DenseNet121(input_shape=input_shape, weights='imagenet', include_top=False)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_array = train_generator.labels\nnormal_freq = len(np.where(l_array == 1)[0]) / len(l_array)\ncovid_freq = len(np.where(l_array == 0)[0]) / len(l_array)\nPneumonia_freq = len(np.where(l_array == 2)[0]) / len(l_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, BatchNormalization, Activation, Dense\n\nnum_classes = len(train_lstnames)\n\n\nx = GlobalAveragePooling2D()(model.output)\n\nx = Dense(units = 512, kernel_initializer='he_normal')(x)\nx = BatchNormalization(axis = -1)(x)\nx = Activation('relu')(x)\nx = Dropout(0.2)(x)\n\nx = Dense(units = num_classes, activation = 'softmax')(x)\n\nfinal_model = Model(inputs = [model.input], outputs = [x])\n\nfinal_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nfinal_model.compile(loss = 'categorical_crossentropy', optimizer=Adam(learning_rate=1e-3, amsgrad=False), metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lrfn(lr_start=0.000002, lr_max=0.00010, \n               lr_min=0, lr_rampup_epochs=8, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n\ndef exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0*0.1**(epoch / s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(lr0=0.01, s = 10)\nlr_scheduler = LearningRateScheduler(exponential_decay_fn)\nmodel_checkpoint = ModelCheckpoint('my_checkpoint.h5', save_best_only=True)\nearly_stop = EarlyStopping(patience = 10, restore_best_weights=True)\n\nclass StopTraining(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs):\n        if logs.get('val_accuracy') >= 0.95:\n            print('Reach the desirable accuracy')\n            self.model.stop_training = True\n            \nstopTrain = StopTraining()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = final_model.fit(train_generator, epochs = 20, validation_data=test_generator, steps_per_epoch=251/64, \n                                    validation_steps=66/16, verbose = 1, callbacks=[lr_scheduler, model_checkpoint, early_stop, stopTrain], class_weight={0 : 0.8, 1:1, 2:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model.save('/kaggle/working/CovidNet.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepoch = history.epoch\n\nplt.plot(epoch, acc, label = 'Training accuracy', color = 'r')\nplt.plot(epoch, val_acc, label = 'Validation accuracy', color = 'b')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.figure()\n\n\nplt.plot(epoch, loss, label = 'Training loss', color = 'r')\nplt.plot(epoch, val_loss, label = 'Validation loss', color = 'b')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_per_types_test = {}\n\nfor idx, test_type_dir in enumerate(test_types_dir):\n    num_spec = len(os.listdir(test_type_dir))\n    type_name = test_lstnames[idx]\n    number_per_types_test[type_name] = num_spec\n    \ntype_number_df_test = pd.DataFrame(data=[number_per_types_test[i] for i in number_per_types_test.keys()], index=number_per_types_test.keys(), columns=['Quantity'])\n\nnumber_random_types = 3\nnumber_random_per_kind = 2\nimage_size = 5\n\nnext_image = generate_random_image(test_lstnames, number_random_types, number_random_per_kind, test_types_dir, type_number_df_test)\n\nplot_image(number_random_types, number_random_per_kind, image_size, next_image, class_names = class_names, model  = final_model, get_prediction = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nnew_model= tf.keras.models.load_model(filepath='/kaggle/working/CovidNet.h5')\nconverter = tf.lite.TFLiteConverter.from_keras_model(new_model)\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}